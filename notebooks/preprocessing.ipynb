{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessings\n",
    "\n",
    "In this notebook we develop and evaluate the various preprocessing both for segmentation and classification which should help make our solution invariant to some data differences and make ML feature more powerfull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import *\n",
    "\n",
    "import imageio\n",
    "import skimage.segmentation\n",
    "import skimage.filters\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clb.dataprep.utils\n",
    "dir_root = r'D:\\Fafa\\MIT\\CellDx\\preprocessing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_3d = os.path.join(dir_root, 'TestNewClasses S2 1024 crop_class_pdlcd_8.tif')\n",
    "data_input_bad_full = imageio.volread(path_3d)\n",
    "data_input_bad = imageio.volread(path_3d)[::,300:500,150:350,::]\n",
    "data_input_bad_normalized = clb.dataprep.utils.rescale_to_float(data_input_bad, float_type='float32')\n",
    "\n",
    "path_3d_labels = os.path.join(dir_root, 'TestNewClasses S2 1024 crop_class_pdlcd_8_segmented.tif')\n",
    "data_input_bad_labels = imageio.volread(path_3d_labels)[::,300:500,150:350]\n",
    "show_all(2,3,data_input_bad[0], data_input_bad[0][::,::,0], data_input_bad_labels[0], data_input_bad[0][::,::,1], data_input_bad[0][::,::,2], data_input_bad_labels[0], scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_3d = os.path.join(dir_root, 'TestNewClasses S1 1024 crop_class_pdlcd_9.tif')\n",
    "data_input = imageio.volread(path_3d)[::,150:350,150:350,::]\n",
    "data_input_normalized = clb.dataprep.utils.rescale_to_float(data_input, float_type='float32')\n",
    "\n",
    "path_3d_labels = os.path.join(dir_root, 'TestNewClasses S1 1024 crop_class_pdlcd_9_segmented.tif')\n",
    "data_input_labels = imageio.volread(path_3d_labels)[::,150:350,150:350]\n",
    "show_all(2,3,data_input[0], data_input[0][::,::,0], data_input_labels[0], data_input[0][::,::,1], data_input[0][::,::,2], data_input_labels[0], scale=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clahe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters.rank import median\n",
    "\n",
    "def median_colour_filter(image, size):\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    for i in range(3):\n",
    "        image[::,::,i] = median(image[::,::,i], disk(size))\n",
    "    return image\n",
    "\n",
    "def clahe(image, size, median, **kwargs):\n",
    "    if median is not None:\n",
    "        image = median_colour_filter(image, median) / 255.0\n",
    "    data_clahe = exposure.equalize_adapthist(image, size, **kwargs)\n",
    "    return data_clahe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "\n",
    "sample = data_input_normalized[0]\n",
    "data_clahe = clahe(sample, 70, median=2, clip_limit=0.015)\n",
    "print(data_clahe.shape, data_clahe.dtype)\n",
    "show_all(3,1,\n",
    "         np.hstack([sample[::,::,0], data_clahe[::,::,0]]), \n",
    "         np.hstack([sample[::,::,1], data_clahe[::,::,1]]), \n",
    "         np.hstack([sample[::,::,2], data_clahe[::,::,2]]), scale=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_bad = data_input_bad_normalized[0]\n",
    "data_bad_clahe = clahe(sample_bad, 70, 2, clip_limit=0.015)\n",
    "show_all(3,1,\n",
    "         np.hstack([sample_bad[::,::,0], data_bad_clahe[::,::,0]]), \n",
    "         np.hstack([sample_bad[::,::,1], data_bad_clahe[::,::,1]]), \n",
    "         np.hstack([sample_bad[::,::,2], data_bad_clahe[::,::,2]]), scale=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clb.classify.feature_extractor as fe\n",
    "\n",
    "print (data_input_bad_normalized.shape, data_input_bad_normalized.dtype)\n",
    "pre_clahe_bad, pre_clahe_labels = fe.preprocess_channel(data_input_bad_normalized[::, ::,::,0], data_input_bad_labels, 'clahe')\n",
    "print (pre_clahe_bad.shape, pre_clahe_bad.dtype)\n",
    "show_all(2,1, np.hstack([sample_bad[::,::,0], pre_clahe_bad[0]]), \n",
    "                        np.hstack([data_input_bad_labels[0], pre_clahe_labels[0]]), scale=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters.rank import median\n",
    "import skimage.filters\n",
    "import scipy.stats\n",
    "import scipy.ndimage\n",
    "\n",
    "def median_colour_filter(image, size):\n",
    "    image = image.copy()\n",
    "    for i in range(3):\n",
    "        image[::,::,i] = median(image[::,::,i], disk(size))\n",
    "    return image\n",
    "\n",
    "def log(image, size, median, **kwargs):\n",
    "    if median is not None:\n",
    "        image = median_colour_filter(image, median) / 255.0\n",
    "    data_clahe = exposure.equalize_adapthist(image, size, **kwargs)\n",
    "    return data_clahe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logas2 = scipy.ndimage.gaussian_laplace(sample[::,::,0], 1)\n",
    "print(logas2.shape)\n",
    "print(scipy.stats.describe(logas2, None))\n",
    "\n",
    "logas2b = scipy.ndimage.gaussian_laplace(sample[::,::,0], 1.5)\n",
    "print(logas2b.shape)\n",
    "print(scipy.stats.describe(logas2b, None))\n",
    "\n",
    "show_all(1,1, np.hstack([logas2, logas2b]), scale=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values = [i / 10 for i in range(1,20, 1)]\n",
    "#res = [scipy.ndimage.gaussian_laplace(sample[::,::,0], v) for v in values ]\n",
    "#show_all(len(res) // 4, 4, *res, scale=40, titles = list(map(str,values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values = [i / 10 for i in range(1,20, 1)]\n",
    "#res = [scipy.ndimage.gaussian_gradient_magnitude(sample[::,::,0], sigma=v) for v in values ]\n",
    "#show_all(len(res) // 4, 4, *res, scale=40, titles = list(map(str,values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logas2 = scipy.ndimage.gaussian_gradient_magnitude(data_input_normalized[::,::,::,0], 1)\n",
    "print(logas2.shape)\n",
    "print(scipy.stats.describe(logas2, None))\n",
    "\n",
    "print(sample.dtype)\n",
    "logas2b = scipy.ndimage.gaussian_gradient_magnitude(data_input_normalized[::,::,::,0], 1.5)\n",
    "print(logas2b.shape, logas2b.dtype)\n",
    "print(scipy.stats.describe(logas2b, None))\n",
    "\n",
    "logasa = scipy.ndimage.gaussian_gradient_magnitude(data_input_normalized[2,::,::,0], 1)\n",
    "print(logasa.shape)\n",
    "print(scipy.stats.describe(logasa, None))\n",
    "\n",
    "logasa2b = scipy.ndimage.gaussian_gradient_magnitude(data_input_normalized[2,::,::,0], 1.5)\n",
    "print(logasa2b.shape, logasa2b.dtype)\n",
    "print(scipy.stats.describe(logasa2b, None))\n",
    "\n",
    "show_all(2,1, np.hstack([logas2[2], logas2b[2]]),\n",
    "         np.hstack([logasa, logasa2b])\n",
    "         , scale=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membrane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clb.dataprep.utils import extract_label_edges\n",
    "\n",
    "def get_edges_only(labels, edge_size=6):\n",
    "    boundaries = extract_label_edges(labels, edge_size)\n",
    "    return labels * boundaries\n",
    "\n",
    "show_all(1,1, np.hstack([data_input_labels[0], get_edges_only(data_input_labels[0], 6)]), scale=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_input_labels.dtype)\n",
    "boundaries = get_edges_only(data_input_labels)\n",
    "print(boundaries.shape, boundaries.dtype)\n",
    "show_all(1,2, data_input_labels[0], boundaries[0], scale=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clb.image_processing import extend_membrane as get_wide_membrane\n",
    "\n",
    "edges = get_edges_only(data_input_labels) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd8_normalized = data_input_normalized[0,::,::,2]\n",
    "labels_slices = data_input_labels[0]\n",
    "edges_slice = edges[0]\n",
    "show_all(3,1, np.hstack([cd8_normalized, get_wide_membrane(cd8_normalized, 1)]), \\\n",
    "          np.hstack([labels_slices * cd8_normalized, labels_slices * get_wide_membrane(cd8_normalized, 1)]), \\\n",
    "         np.hstack([edges_slice * cd8_normalized, edges_slice * get_wide_membrane(cd8_normalized, 1)]), scale=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pdl1_normalized = data_input_normalized[0,::,::,1]\n",
    "show_all(1,1, np.hstack([pdl1_normalized, get_wide_membrane(pdl1_normalized, 1)]), scale=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels_slices = data_input_labels[0]\n",
    "edges_slice = edges[0]\n",
    "show_all(3,1, np.hstack([pdl1_normalized, get_wide_membrane(pdl1_normalized, 1)]), \\\n",
    "          np.hstack([labels_slices * pdl1_normalized, labels_slices * get_wide_membrane(pdl1_normalized, 1)]), \\\n",
    "         np.hstack([edges_slice * pdl1_normalized, edges_slice * get_wide_membrane(pdl1_normalized, 1)]), scale=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand outside "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges_extended(labels, edge_size=6):\n",
    "    boundaries = extract_label_edges(labels, edge_size)\n",
    "    return labels * boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilated = skimage.morphology.dilation(labels_slices, disk(4))\n",
    "\n",
    "dilated_respect = dilated.copy()\n",
    "dilated_respect[labels_slices != 0] = labels_slices[labels_slices != 0]\n",
    "\n",
    "edges_only = get_edges_only(dilated_respect, 10)\n",
    "\n",
    "dilated_difference = dilated_respect * (labels_slices == 0)\n",
    "\n",
    "edges_only_small = get_edges_only(labels_slices, 4)\n",
    "dilated_diff_with_edges = dilated_difference.copy()\n",
    "dilated_diff_with_edges[dilated_diff_with_edges == 0] = edges_only_small[dilated_diff_with_edges == 0]\n",
    "\n",
    "show_all(5,3, \n",
    "         pdl1_normalized, get_wide_membrane(pdl1_normalized, 1) * (get_edges_extended(labels_slices, 6) != 0), get_edges_extended(labels_slices, 6), \n",
    "         labels_slices, dilated, dilated_respect, \n",
    "         edges_only, get_wide_membrane(pdl1_normalized, 1) * edges_only, pdl1_normalized * edges_only, \n",
    "         dilated_difference, get_wide_membrane(pdl1_normalized, 1) * dilated_difference, pdl1_normalized * dilated_difference, \n",
    "         dilated_diff_with_edges, get_wide_membrane(pdl1_normalized, 1) * dilated_diff_with_edges, pdl1_normalized * dilated_diff_with_edges,\n",
    "         scale=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import clb.classify.feature_extractor as fe\n",
    "\n",
    "importlib.reload(clb.image_processing)\n",
    "importlib.reload(fe)\n",
    "print (data_input_bad_normalized.shape, data_input_bad_normalized.dtype)\n",
    "pre_memb_bad, pre_memb_labels = fe.preprocess_channel(data_input_bad_normalized[::, ::,::,2], data_input_bad_labels, 'memb')\n",
    "print ('volume:', pre_memb_bad.shape, pre_memb_bad.dtype)\n",
    "print ('labels:', pre_memb_labels.shape, pre_memb_labels.dtype)\n",
    "show_all(2,1, np.hstack([sample_bad[::,::,2], pre_memb_bad[0]]), \n",
    "                        np.hstack([data_input_bad_labels[0], pre_memb_labels[0]]), scale=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(clb.image_processing)\n",
    "importlib.reload(fe)\n",
    "print (data_input_bad_normalized.shape, data_input_bad_normalized.dtype)\n",
    "pre_memb_bad, pre_memb_labels = fe.preprocess_channel(data_input_bad_normalized[::, ::,::,2], data_input_bad_labels, 'memb')\n",
    "print ('volume:', pre_memb_bad.shape, pre_memb_bad.dtype)\n",
    "print ('labels:', pre_memb_labels.shape, pre_memb_labels.dtype)\n",
    "show_all(2,1, np.hstack([sample_bad[::,::,2], pre_memb_bad[0]]), \n",
    "                        np.hstack([data_input_bad_labels[0], pre_memb_labels[0]]), scale=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clb.classify.feature_extractor as fe\n",
    "\n",
    "def overlay_sample_boundaries(input_sample_single, mask_image, colour=(30, 0, 0)):\n",
    "    input_sample = np.stack((input_sample_single,)*3, axis=-1)\n",
    "    boundary_sample = skimage.segmentation.find_boundaries(mask_image)\n",
    "    input_sample[boundary_sample != 0] += colour\n",
    "    input_sample[mask_image != 0] += (0, 30, 0)\n",
    "    return input_sample\n",
    "\n",
    "def summary_for_data(volume, labels, slice_num=None):\n",
    "    slice_num = slice_num or len(volume) // 2\n",
    "    org_vol, org_labels = volume[slice_num], labels[slice_num]\n",
    "    org_overlay = overlay_sample_boundaries(org_vol, org_labels)\n",
    "    \n",
    "    clahe = fe.preprocess_channel(volume, labels, 'clahe')\n",
    "    clahe_vol, clahe_labels = clahe[0][slice_num], clahe[1][slice_num]\n",
    "    clahe_overlay = overlay_sample_boundaries(clahe_vol, clahe_labels)\n",
    "    \n",
    "    edges = fe.preprocess_channel(volume, labels, 'edges')\n",
    "    edges_vol, edges_labels = edges[0][slice_num], edges[1][slice_num]\n",
    "    edges_overlay = overlay_sample_boundaries(edges_vol, edges_labels)\n",
    "    \n",
    "    memb = fe.preprocess_channel(volume, labels, 'memb')\n",
    "    memb_vol, memb_labels = memb[0][slice_num], memb[1][slice_num]\n",
    "    memb_overlay = overlay_sample_boundaries(memb_vol, memb_labels)\n",
    "    \n",
    "    return show_all(3,1, np.hstack([org_vol, clahe_vol, edges_vol, memb_vol]), \n",
    "                        np.hstack([org_labels, clahe_labels, edges_labels, memb_labels]), \n",
    "                      np.hstack([org_overlay, clahe_overlay, edges_overlay, memb_overlay]), \n",
    "                    scale=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_for_data(data_input_bad_normalized[::,::,::,0], data_input_bad_labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_for_data(data_input_bad_normalized[::,::,::,1], data_input_bad_labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_for_data(data_input_bad_normalized[::,::,::,2], data_input_bad_labels, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
